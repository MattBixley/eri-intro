[
  {
    "objectID": "slurm.html",
    "href": "slurm.html",
    "title": "Slurm",
    "section": "",
    "text": "Some helpful slurm commands to see how your job ran or what is happening on the cluster with more options at the\neRI Slurm Reference Guide\n\nSlurm\n\n\n\nCommand\nExample\nDescription\n\n\n\n\nsbatch\nsbatch submit.sl\nSubmits the Slurm script submit.sl\n\n\nsqueue\nsqueue\nsqueue --me\nsqueue -p compute\nDisplays entire queue.\nDisplays your queued jobs.\nDisplays queued jobs on the compute partition.\n\n\nsacct\nsacct\nsacct -S 2024-01-01\nsacct -j 123456\nDisplays all the jobs run by you that day.\nDisplays all the jobs run by you since the 1st Jan 2024\nDisplays job 123456\n\n\nscancel\nscancel 123456\nscancel --me\nCancels job 123456\nCancels all your jobs.\n\n\nsshare\nsshare -U\nShows the Fair Share scores for all projects of which you are a member.\n\n\nsinfo\nsinfo\nShows the current state of the Slurm partitions.\n\n\n\n\n\nsbatch\n\n\n\n\n\n\n\n\nCommand\nExample\nDescription\n\n\n\n\n–job-name\n#SBATCH --job-name=MyJob\nThe name that will appear when using squeue or sacct\n\n\n–account\n#SBATCH --account=2024-mjb-sandbox\nThe account that usage will be recorded for.\n\n\n–time\n#SBATCH --time=DD-HH:MM:SS\nJob max walltime\n\n\n\n–mem\n#SBATCH --mem=512MB\nMemory required per node.\n\n\n–partition\n#SBATCH --partition=compute\nSpecified job partition\n\n\n–output\n#SBATCH --output=%j_output.out\nStandard output file.\n\n\n–mail-user\n#SBATCH --mail-user=matt.bixley@agresearch.co.nz\nAddress to send mail notifications.\n\n\n–mail-type\n#SBATCH --mail-type=ALL\n#SBATCH --mail-type=TIME_LIMIT_80\nWill send a mail notification at BEGIN END FAIL\nWill send message at 80% walltime\n\n\n–no-requeue\n#SBATCH --no-requeue\n\nWill stop job being requeued in the case of node failure."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "A demo, building knowledge and open forum around how to get the best use out of your eRI Compute Cluster. What we won’t be covering is Jupyter/RStudio/Open on Demand.\n\nFramework\n\nAccessing\n\nHow to get there\nDirectories\n\nCluster Setup\n\nPlatform Differences\n\nWorking\n\nrunning jobs\ndo’s and dont’s\nefficiency\nfairshare\n\nDiscussion\n\nLimits\nPriorities\nReservations\n\n\n\nResources\nGoogle Sheet -\nSupport Pages - AgResearch eResearch Infrastructure\nSlurm Guide - Slurm Cheatsheet & Slurm Website\nFinding Software - Modules"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "cluster.html",
    "href": "cluster.html",
    "title": "Cluster Architecture",
    "section": "",
    "text": "Cluster setup and the resources available. General information about the cluster and differences between, Legacy/eRI/NeSI can be found at Differences\nOIn the custer, the sinfo command can show the current state of each node.\n\nS:C:T means, sockets, cores and threads and CPUS = S*C*T and gvies the number of possible tasks for that node.\n\nThe interactive and vgpu nodes are in the Open on Demand/Jupyter space and will eventually not be visible as a resource on the cluster, but we will use them for the Demo.\n\nlogin-0 ~ $ sinfo\nPARTITION AVAIL JOB_SIZE  TIMELIMIT   CPUS  S:C:T   NODES STATE      NODELIST\ncompute*  up    1-infini 14-00:00:0    256 2:64:2       2 mixed      compute-[0,5]\ncompute*  up    1-infini 14-00:00:0    256 2:64:2       1 allocated  compute-2\ncompute*  up    1-infini 14-00:00:0    256 2:64:2       3 idle       compute-[1,3-4]\ngpu       up    1-infini 14-00:00:0     96 2:24:2       1 idle       gpu-0\nhugemem   up    1-infini 14-00:00:0    256 2:64:2       1 mixed      hugemem-0\nhugemem   up    1-infini 14-00:00:0    256 2:64:2       1 idle       hugemem-1\ninteracti up    1-infini 60-00:00:0      8  8:1:1       1 mixed      interactive-0\ninteracti up    1-infini 60-00:00:0      8  8:1:1       2 idle       interactive-[1-2]\nvgpu      up    1-infini 60-00:00:0     32 32:1:1       4 idle       vgpu-[0-3]\n\nMore information about resources and the state of each node can be gained from the command sinfo -N --Format=nodelist,cpusload,cpusState,FreeMem,AllocMem,Memory\n\nlogin-0 ~ $ sinfo -N --Format=nodelist,cpusload,cpusState,FreeMem,AllocMem,Memory\nNODELIST            CPU_LOAD            CPUS(A/I/O/T)       FREE_MEM            ALLOCMEM            MEMORY              \ncompute-0           0.29                18/238/0/256        978099              146072              980163              \ncompute-1           0.02                0/256/0/256         1016984             0                   980163              \ncompute-2           57.25               256/0/0/256         869759              262144              980163              \ncompute-3           0.00                0/256/0/256         1016450             0                   980163              \ncompute-4           0.00                0/256/0/256         1015908             0                   980163              \ncompute-5           58.02               96/160/0/256        947861              98304               980163              \ngpu-0               0.08                0/96/0/96           505645              0                   489916              \nhugemem-0           40.21               40/216/0/256        4022021             307200              3910416             \nhugemem-1           0.02                0/256/0/256         4100992             0                   3910416             \ninteractive-0       0.01                2/6/0/8             10838               8620                15217               \ninteractive-1       0.00                0/8/0/8             12178               0                   15217               \ninteractive-2       0.04                0/8/0/8             12116               0                   15217               \nvgpu-0              0.00                0/32/0/32           446262              0                   428894              \nvgpu-1              0.00                0/32/0/32           446914              0                   428894              \nvgpu-2              0.00                0/32/0/32           446902              0                   428894              \nvgpu-3              0.03                0/32/0/32           446940              0                   428894              \n\n\nLimits"
  },
  {
    "objectID": "jobs.html",
    "href": "jobs.html",
    "title": "Jobs",
    "section": "",
    "text": "Submitting jobs, requirements, fairshare\n\nCreating a batch script\n\n#!/bin/bash -e \n#SBATCH --job-name=SerialJob # job name (shows up in the queue) \n#SBATCH --account=2024-mjb-sandbox # project to record usage against \n#SBATCH --time=00:01:00 # Walltime (days-HH:MM:SS) \n#SBATCH --mem=512MB # Memory in MB or GB\n\npwd # Prints working directory\n\n\n\nSubmitting\n\nsbatch myjob.sl\n\n\n\nInteractive Jobs\n\nsrun --cpus-per-task 2 --account 2024-mjb-sandbox --mem6G -p compute --time 01:00:00 --pty bash--partition compute\n\n\n\nJob Efficiency\nInefficient Memory usage that allows 4 Jobs per node\n\nlogin-0 ~ $ seff 391751\n\nJob ID: 394314 \nArray Job ID: 391751_28 \nCluster: eri User/Group: bixleym@agresearch.co.nz/bixleym@agresearch.co.nz \nState: COMPLETED (exit code 0) \nNodes: 1 \nCores per node: 32 \nCPU Utilized: 79-07:10:55 \nCPU Efficiency: 76.80% of 103-06:03:12 \ncore-walltime Job Wall-clock time: 3-05:26:21\nMemory Utilized: 25.34 GB \nMemory Efficiency: 9.90% of 256.00 GB\n\nSimilar Job - efficient memory request, would allow for 8 Job per node.\n\nlogin-0 ~ $ seff 401588\nJob ID: 432626\nArray Job ID: 401588\nCluster: eri\nUser/Group: bixleym@agresearch.co.nz/bixleym@agresearch.co.nz\nState: COMPLETED (exit code 0)\nNodes: 1\nCores per node: 32\nCPU Utilized: 37-22:09:27\nCPU Efficiency: 82.98% of 45-16:52:48 core-walltime\nJob Wall-clock time: 1-10:16:39\nMemory Utilized: 27.16 GB\nMemory Efficiency: 84.86% of 32.00 GB\n\n\n\nFairshare\nRelative use of the cluster. Everyone is assumed to have an equal proportion of the cluster or and equal right to use it. If you use a lot more than everyone else you Fairshare will decrease and you job priority will decrease relative to others. That decays over time (~1 week)\n\n\nlogin-0 ~ $ sshare -U\nAccount                    User  RawShares  NormShares    RawUsage  EffectvUsage  FairShare \n-------------------- ---------- ---------- ----------- ----------- ------------- ---------- \n2023-nesi_slurm_tes+ bixleym@a+     parent    0.038462        3400      0.251494   0.788462"
  }
]